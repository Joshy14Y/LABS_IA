{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LAB EXTRA 2\n",
    "### Hecho por: Joshua Sancho y Steven Solís"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1986640934d8e4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importar Librerías"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afe20f942dfbc7d1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T04:35:39.852610Z",
     "start_time": "2024-05-14T04:35:39.830603800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Procesamiento de Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e87e93927f4b1d7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def resize_images_and_save(dataset_path, save_resized_path):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_resized_path):\n",
    "        os.makedirs(save_resized_path)\n",
    "    \n",
    "    # Loop through each class folder\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        \n",
    "        # Create a directory for the resized images of this class\n",
    "        class_save_path = os.path.join(save_resized_path, class_name)\n",
    "        if not os.path.exists(class_save_path):\n",
    "            os.makedirs(class_save_path)\n",
    "        \n",
    "        # Loop through each image file in the class folder\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Read and convert the image to grayscale\n",
    "            image = cv2.imread(image_path)\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Resize the grayscale image to 40x40\n",
    "            resized_image = cv2.resize(gray_image, (40, 40))\n",
    "            \n",
    "            # Save the resized image\n",
    "            save_image_path = os.path.join(class_save_path, image_file)\n",
    "            cv2.imwrite(save_image_path, resized_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T04:35:41.048877400Z",
     "start_time": "2024-05-14T04:35:41.016869800Z"
    }
   },
   "id": "25ba9b3accfc6290"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resize_images_and_save(r'dataset/train', r'dataset/train_resized')\n",
    "resize_images_and_save(r'dataset/valid',  r'dataset/val_resized')\n",
    "resize_images_and_save(r'dataset/test',  r'dataset/test_resized')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T04:33:09.940957400Z",
     "start_time": "2024-05-14T04:33:09.940957400Z"
    }
   },
   "id": "c64af8382570c215"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dataframe_from_images(dataset_path):\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each class folder\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        \n",
    "        # Loop through each image file in the class folder\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Append the image path and class name to the data list\n",
    "            data.append({'image_path': image_path, 'class': class_name})\n",
    "    \n",
    "    # Create a pandas DataFrame from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-14T04:33:09.941957Z"
    }
   },
   "id": "c37459b8156d887e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = create_dataframe_from_images(r'../LAB_Extra_2/dataset/train_resized')\n",
    "test = create_dataframe_from_images(r'../LAB_Extra_2/dataset/test_resized')\n",
    "val = create_dataframe_from_images(r'../LAB_Extra_2/dataset/val_resized')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-14T04:33:09.943957900Z"
    }
   },
   "id": "e45c7808cf8a5ee7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define data augmentation and normalization parameters for training data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,      # Rotate images randomly up to 40 degrees\n",
    "    width_shift_range=0.2,  # Shift images horizontally up to 20% of the width\n",
    "    height_shift_range=0.2, # Shift images vertically up to 20% of the height\n",
    "    shear_range=0.2,        # Shear intensity\n",
    "    zoom_range=0.2,         # Zoom in randomly up to 20%\n",
    "    horizontal_flip=True,   # Flip images horizontally\n",
    "    fill_mode='nearest'     # Fill in newly created pixels after rotation or shifting\n",
    ")\n",
    "\n",
    "# Create a data generator for training data with one-hot encoded labels\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../LAB_Extra_2/dataset/train',\n",
    "    target_size=(40, 40),\n",
    "    batch_size=5,\n",
    "    class_mode='binary',  # Change class_mode to 'categorical'\n",
    "    shuffle=True)  # Shuffle the data\n",
    "\n",
    "# Define data augmentation and normalization parameters for validation data\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a data generator for validation data with one-hot encoded labels\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '../LAB_Extra_2/dataset/valid',\n",
    "    target_size=(40, 40),\n",
    "    batch_size=5,\n",
    "    class_mode='binary',  # Change class_mode to 'categorical'\n",
    "    shuffle=False)  # No need to shuffle validation data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-14T04:33:09.945957700Z"
    }
   },
   "id": "9695994b047e6fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arquitectura de Red Neuronal Convolucional"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed4235d932b395f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(40, 40, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-14T04:33:09.946958Z"
    }
   },
   "id": "f8917ab259bf087d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenamiento"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b5c6074735850cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define model checkpoint callback to save the best model\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Compile the model with a learning rate of 0.001\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',  # Change the loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 100 epochs\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=100, callbacks=[model_checkpoint])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-14T04:33:09.947958200Z"
    }
   },
   "id": "e84950e9240ffd3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the training metrics\n",
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "\n",
    "# Get the validation metrics\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-14T04:33:09.949959300Z"
    }
   },
   "id": "44e54655c1d2cc9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusión\n",
    "Se logró mejorar la precisión del modelo a un 99% con una pérdida del 4% en valores de validación!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67e9c98919a95cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
